{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-15T08:12:34.781028Z",
     "start_time": "2025-07-15T08:12:33.755910Z"
    }
   },
   "source": [
    "import os\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import SentenceTransformersTokenTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from utils import clean\n",
    "from dotenv import load_dotenv"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T08:12:37.709622Z",
     "start_time": "2025-07-15T08:12:37.702511Z"
    }
   },
   "cell_type": "code",
   "source": "load_dotenv()",
   "id": "17b8828b6f6e9f38",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T08:12:39.205273Z",
     "start_time": "2025-07-15T08:12:39.201861Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dir = \"../../documents\"\n",
    "documents_path = os.listdir(dir)\n",
    "documents_path = [f\"{dir}/{file}\" for file in documents_path]"
   ],
   "id": "417949d5084d6f1f",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T08:12:45.595280Z",
     "start_time": "2025-07-15T08:12:40.388797Z"
    }
   },
   "cell_type": "code",
   "source": [
    "documents = []\n",
    "for file in documents_path:\n",
    "    loader = PyPDFLoader(file)\n",
    "    loaded_docs = loader.load()\n",
    "    \n",
    "    for doc in loaded_docs:\n",
    "        doc.page_content = clean(doc.page_content)\n",
    "    \n",
    "    documents.extend(loaded_docs)"
   ],
   "id": "21e55c19daa2de7f",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T08:13:18.119072Z",
     "start_time": "2025-07-15T08:13:14.967080Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text_splitter = SentenceTransformersTokenTextSplitter(tokens_per_chunk=384, chunk_overlap=40)\n",
    "chunks = text_splitter.split_documents(documents)"
   ],
   "id": "414fef6a67e26d5b",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T08:13:35.038023Z",
     "start_time": "2025-07-15T08:13:23.321052Z"
    }
   },
   "cell_type": "code",
   "source": [
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "embeddings = embedding_model.embed_documents([chunk.page_content for chunk in chunks])"
   ],
   "id": "27e4c9975e63a432",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T08:13:48.373076Z",
     "start_time": "2025-07-15T08:13:38.922310Z"
    }
   },
   "cell_type": "code",
   "source": "vectorstore = FAISS.from_documents(documents=chunks, embedding=embedding_model)",
   "id": "f3d02e8f0d8f678b",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T08:13:57.734994Z",
     "start_time": "2025-07-15T08:13:57.712982Z"
    }
   },
   "cell_type": "code",
   "source": [
    "retriever  = vectorstore.as_retriever()\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", temperature=0.2)\n",
    "\n",
    "rag_pipeline = RetrievalQA.from_chain_type(llm=llm, retriever=retriever, return_source_documents=True)"
   ],
   "id": "2191aa1393badfd7",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T08:14:02.321325Z",
     "start_time": "2025-07-15T08:14:00.079620Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query = \"how use nural network in nlp\"\n",
    "response = rag_pipeline.invoke(query)\n",
    "\n",
    "print(\"Answer:\")\n",
    "print(response[\"result\"])"
   ],
   "id": "920aca02a869a1e5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      "Based on the context you provided, here's how neural networks are used in NLP:\n",
      "\n",
      "*   **Classification Tasks:** Neural networks can be applied to NLP classification tasks like sentiment analysis. Instead of using hand-built features, they learn features from the data by representing words as embeddings (like word2vec or GloVe).\n",
      "*   **Sequence Modeling:** Neural networks are used for sequence modeling tasks like part-of-speech tagging.\n",
      "*   **Language Modeling:** Neural networks can be used for language modeling.\n",
      "*   **Recurrent Neural Networks (RNNs):** RNNs, including Elman networks and LSTMs, are particularly effective for language-related tasks.\n",
      "*   **Feature Extraction:** Deep learning enables neural networks to learn features from data, using word embeddings as input.\n",
      "*   **Combination with Embeddings:** Word embeddings (like word2vec or GloVe) are often used as input to neural networks for NLP tasks.\n",
      "*   **Flexible Architectures:** By combining feedforward networks with vectors, complex networks can be treated as modules that can be combined in creative ways. Common architectures used in language processing with RNNs include stacked RNNs.\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T08:15:03.352421Z",
     "start_time": "2025-07-15T08:15:02.733359Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query = \"who author this book\"\n",
    "response = rag_pipeline.invoke(query)\n",
    "\n",
    "print(\"Answer:\")\n",
    "print(response[\"result\"])"
   ],
   "id": "ffbdeaf4f8a2e171",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      "Based on the provided text, the book \"Machine Learning: A Probabilistic Perspective\" was written by Murphy, K. P.\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T08:15:11.821929Z",
     "start_time": "2025-07-15T08:15:11.166137Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query = \"this book explain the lstm and rnn\"\n",
    "response = rag_pipeline.invoke(query)\n",
    "\n",
    "print(\"Answer:\")\n",
    "print(response[\"result\"])"
   ],
   "id": "33c132233e14cce9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      "Yes, the book explains both LSTM (Long Short-Term Memory) networks and RNNs (Recurrent Neural Networks).\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T08:15:18.981116Z",
     "start_time": "2025-07-15T08:15:14.991793Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query = \"who best naive bays or transformer\"\n",
    "response = rag_pipeline.invoke(query)\n",
    "\n",
    "print(\"Answer:\")\n",
    "print(response[\"result\"])"
   ],
   "id": "37ab015ac908bd0b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      "Naive Bayes and Transformers are suited for different tasks. Naive Bayes is a classification algorithm, while Transformers are a type of neural network architecture often used for sequence-to-sequence tasks. Naive Bayes is easy to implement and fast to train, and can work well on very small datasets or short documents. Transformers are very modular and use multi-head attention, where each head might attend to the context for different purposes.\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T08:15:45.836353Z",
     "start_time": "2025-07-15T08:15:45.003039Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query = \"In this book what the chapter number for  vector semantic\"\n",
    "response = rag_pipeline.invoke(query)\n",
    "\n",
    "print(\"Answer:\")\n",
    "print(response[\"result\"])"
   ],
   "id": "7139c4ce82c0388a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      "Based on the provided text, vector semantics is discussed in chapter 6.2.\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T08:15:53.901714Z",
     "start_time": "2025-07-15T08:15:48.897743Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query = \"what the transformer use case\"\n",
    "response = rag_pipeline.invoke(query)\n",
    "\n",
    "print(\"Answer:\")\n",
    "print(response[\"result\"])"
   ],
   "id": "8b071d8c5ab12f0e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      "Based on the text, transformers are used for:\n",
      "\n",
      "*   Building language models.\n",
      "*   Mapping an input vector to an output vector by adding vectors from prior tokens, weighted by how relevant they are for the processing of the current word.\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T08:16:09.982965Z",
     "start_time": "2025-07-15T08:16:09.036063Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query = \"what the naive bays use case\"\n",
    "response = rag_pipeline.invoke(query)\n",
    "\n",
    "print(\"Answer:\")\n",
    "print(response[\"result\"])"
   ],
   "id": "68fa742aff4101ea",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      "Naive Bayes is easy to implement and very fast to train, so it’s a reasonable approach to use in some situations. Naive Bayes can work extremely well (sometimes even better than logistic regression) on very small datasets or short documents.\n"
     ]
    }
   ],
   "execution_count": 16
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
