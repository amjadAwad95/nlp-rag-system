{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-15T08:01:52.689696Z",
     "start_time": "2025-07-15T08:01:51.620397Z"
    }
   },
   "source": [
    "import os\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import SentenceTransformersTokenTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from utils import clean\n",
    "from dotenv import load_dotenv"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T08:01:53.998381Z",
     "start_time": "2025-07-15T08:01:53.992335Z"
    }
   },
   "cell_type": "code",
   "source": "load_dotenv()",
   "id": "17b8828b6f6e9f38",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T08:01:56.054924Z",
     "start_time": "2025-07-15T08:01:56.051496Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dir = \"../../documents\"\n",
    "documents_path = os.listdir(dir)\n",
    "documents_path = [f\"{dir}/{file}\" for file in documents_path]"
   ],
   "id": "417949d5084d6f1f",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T08:02:02.563848Z",
     "start_time": "2025-07-15T08:01:57.713129Z"
    }
   },
   "cell_type": "code",
   "source": [
    "documents = []\n",
    "for file in documents_path:\n",
    "    loader = PyPDFLoader(file)\n",
    "    loaded_docs = loader.load()\n",
    "    \n",
    "    for doc in loaded_docs:\n",
    "        doc.page_content = clean(doc.page_content)\n",
    "    \n",
    "    documents.extend(loaded_docs)"
   ],
   "id": "21e55c19daa2de7f",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T08:02:24.167328Z",
     "start_time": "2025-07-15T08:02:21.158307Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text_splitter = SentenceTransformersTokenTextSplitter(tokens_per_chunk=200, chunk_overlap=20)\n",
    "chunks = text_splitter.split_documents(documents)"
   ],
   "id": "414fef6a67e26d5b",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T08:02:57.549481Z",
     "start_time": "2025-07-15T08:02:54.993588Z"
    }
   },
   "cell_type": "code",
   "source": [
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "# embeddings = embedding_model.embed_documents([chunk.page_content for chunk in chunks])"
   ],
   "id": "27e4c9975e63a432",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T08:03:13.916108Z",
     "start_time": "2025-07-15T08:03:00.427174Z"
    }
   },
   "cell_type": "code",
   "source": "vectorstore = FAISS.from_documents(documents=chunks, embedding=embedding_model)",
   "id": "f3d02e8f0d8f678b",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T08:03:19.407537Z",
     "start_time": "2025-07-15T08:03:19.388336Z"
    }
   },
   "cell_type": "code",
   "source": [
    "retriever  = vectorstore.as_retriever()\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", temperature=0.2)\n",
    "\n",
    "rag_pipeline = RetrievalQA.from_chain_type(llm=llm, retriever=retriever, return_source_documents=True)"
   ],
   "id": "2191aa1393badfd7",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T08:03:23.620166Z",
     "start_time": "2025-07-15T08:03:21.805992Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query = \"how use nural network in nlp\"\n",
    "response = rag_pipeline.invoke(query)\n",
    "\n",
    "print(\"Answer:\")\n",
    "print(response[\"result\"])"
   ],
   "id": "920aca02a869a1e5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      "Based on the text, here's how neural networks are used in NLP:\n",
      "\n",
      "*   **Classification Tasks:** Feedforward networks can be applied to NLP classification tasks like sentiment analysis.\n",
      "*   **Learning Features from Data:** Instead of using hand-built features, neural networks can learn features from data by representing words as embeddings (like word2vec or GloVe).\n",
      "*   **Input Representation:**  A simple baseline is to apply a pooling function to the embeddings of all the words in the input.\n",
      "*   **Sequence Modeling:** Recurrent Neural Networks (RNNs) are used for sequence modeling tasks like part-of-speech tagging.\n",
      "*   **Language Modeling:** Neural networks are used for language modeling.\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T08:05:23.119004Z",
     "start_time": "2025-07-15T08:05:22.115591Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query = \" author this book\"\n",
    "response = rag_pipeline.invoke(query)\n",
    "\n",
    "print(\"Answer:\")\n",
    "print(response[\"result\"])"
   ],
   "id": "ffbdeaf4f8a2e171",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      "The book \"Inference in an Authorship Problem\" was authored by Mosteller, F. and Wallace, D. L. in 1963. They also authored \"Inference and Disputed Authorship: The Federalist\" in 1964.\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T08:05:27.280617Z",
     "start_time": "2025-07-15T08:05:26.706787Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query = \"this book explain the lstm and rnn\"\n",
    "response = rag_pipeline.invoke(query)\n",
    "\n",
    "print(\"Answer:\")\n",
    "print(response[\"result\"])"
   ],
   "id": "33c132233e14cce9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      "Yes, this book explains both LSTMs (Long Short-Term Memory networks) and RNNs (Recurrent Neural Networks).\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T08:05:57.679056Z",
     "start_time": "2025-07-15T08:05:56.764517Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query = \"who best naive bays or transformer\"\n",
    "response = rag_pipeline.invoke(query)\n",
    "\n",
    "print(\"Answer:\")\n",
    "print(response[\"result\"])"
   ],
   "id": "37ab015ac908bd0b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      "Naive Bayes is easy to implement and fast to train, and can work extremely well (sometimes even better than logistic regression) on very small datasets or short documents. Transformers have multi-head attention layer, feedforward networks and layer normalization steps.\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T08:06:25.459663Z",
     "start_time": "2025-07-15T08:06:24.552840Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query = \"In this book what the chapter number for  vector semantic\"\n",
    "response = rag_pipeline.invoke(query)\n",
    "\n",
    "print(\"Answer:\")\n",
    "print(response[\"result\"])"
   ],
   "id": "7139c4ce82c0388a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      "Based on the provided text, vector semantics is discussed in chapter 6.2.\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T08:06:31.589249Z",
     "start_time": "2025-07-15T08:06:30.248984Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query = \"what the transformer use case\"\n",
    "response = rag_pipeline.invoke(query)\n",
    "\n",
    "print(\"Answer:\")\n",
    "print(response[\"result\"])"
   ],
   "id": "8b071d8c5ab12f0e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      "Transformers are non-recurrent networks based on multi-head attention, a kind of self-attention. A multi-head attention computation takes an input vector and maps it to an output by adding in vectors from prior tokens, weighted by how relevant they are for the processing of the current word. Attention can be thought of as a way to build contextual representations of a tokenâ€™s meaning by attending to and integrating information from surrounding tokens, helping the model learn how tokens relate to each other over large spans.\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T08:07:03.735890Z",
     "start_time": "2025-07-15T08:07:02.990227Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query = \"what the naive bays use case\"\n",
    "response = rag_pipeline.invoke(query)\n",
    "\n",
    "print(\"Answer:\")\n",
    "print(response[\"result\"])"
   ],
   "id": "68fa742aff4101ea",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      "Naive Bayes is a reasonable approach for the following use cases:\n",
      "\n",
      "*   Very small datasets\n",
      "*   Short documents\n",
      "*   When ease of implementation and speed of training are important (no optimization step)\n"
     ]
    }
   ],
   "execution_count": 21
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
