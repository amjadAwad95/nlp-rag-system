{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-15T09:14:46.597870Z",
     "start_time": "2025-07-15T09:14:45.793890Z"
    }
   },
   "source": [
    "import os\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import SentenceTransformersTokenTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_mistralai import ChatMistralAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from utils import clean\n",
    "from dotenv import load_dotenv"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T09:14:47.594299Z",
     "start_time": "2025-07-15T09:14:47.587298Z"
    }
   },
   "cell_type": "code",
   "source": "load_dotenv()",
   "id": "17b8828b6f6e9f38",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T09:14:50.718043Z",
     "start_time": "2025-07-15T09:14:50.712829Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dir = \"../../documents\"\n",
    "documents_path = os.listdir(dir)\n",
    "documents_path = [f\"{dir}/{file}\" for file in documents_path]"
   ],
   "id": "417949d5084d6f1f",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T09:14:57.234636Z",
     "start_time": "2025-07-15T09:14:52.367075Z"
    }
   },
   "cell_type": "code",
   "source": [
    "documents = []\n",
    "for file in documents_path:\n",
    "    loader = PyPDFLoader(file)\n",
    "    loaded_docs = loader.load()\n",
    "    \n",
    "    for doc in loaded_docs:\n",
    "        doc.page_content = clean(doc.page_content)\n",
    "    \n",
    "    documents.extend(loaded_docs)"
   ],
   "id": "21e55c19daa2de7f",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "text_splitter = SentenceTransformersTokenTextSplitter(tokens_per_chunk=100, chunk_overlap=10)\n",
    "chunks = text_splitter.split_documents(documents)"
   ],
   "id": "414fef6a67e26d5b",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T09:15:51.543606Z",
     "start_time": "2025-07-15T09:15:43.908679Z"
    }
   },
   "cell_type": "code",
   "source": [
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "# embeddings = embedding_model.embed_documents([chunk.page_content for chunk in chunks])"
   ],
   "id": "27e4c9975e63a432",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T09:16:15.006158Z",
     "start_time": "2025-07-15T09:16:02.645508Z"
    }
   },
   "cell_type": "code",
   "source": "vectorstore = FAISS.from_documents(documents=chunks, embedding=embedding_model)",
   "id": "f3d02e8f0d8f678b",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T09:22:21.632196Z",
     "start_time": "2025-07-15T09:22:21.626586Z"
    }
   },
   "cell_type": "code",
   "source": [
    "retriever  = vectorstore.as_retriever()\n",
    "llm = ChatMistralAI(model=\"mistral-medium-latest\", temperature=0.8, max_retries=2)\n",
    "\n",
    "rag_pipeline = RetrievalQA.from_chain_type(llm=llm, retriever=retriever, return_source_documents=True)"
   ],
   "id": "2191aa1393badfd7",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T09:22:29.303333Z",
     "start_time": "2025-07-15T09:22:23.594373Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query = \"how use nural network in nlp\"\n",
    "response = rag_pipeline.invoke(query)\n",
    "\n",
    "print(\"Answer:\")\n",
    "print(response[\"result\"])"
   ],
   "id": "920aca02a869a1e5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      "The provided context discusses the application of feedforward networks and recurrent neural networks (RNNs) in natural language processing (NLP) tasks, particularly for sentiment analysis and language modeling. Here are some key points on how neural networks are used in NLP based on the context:\n",
      "\n",
      "1. **Feedforward Networks for Classification**:\n",
      "   - **Sentiment Analysis**: Feedforward networks can be used for classification tasks like sentiment analysis. This involves using traditional hand-built features of the input text, such as lexicon words and word counts, to determine the sentiment of a given text.\n",
      "\n",
      "2. **Neural Language Modeling**:\n",
      "   - **Fixed Context Input**: Feedforward neural language models use a fixed context input to a weight matrix. This means that the network takes a specific number of previous tokens (words or characters) as input to predict the next token.\n",
      "   - **RNNs for Sequential Data**: RNNs are particularly useful for processing sequential data. They can handle sequences of word or character embeddings and produce outputs that are useful for predicting words. The context mentions stacked RNNs, which involve multiple layers of RNNs to capture more complex patterns in the data.\n",
      "\n",
      "3. **Combining Networks**:\n",
      "   - Neural networks can be combined in creative ways by treating complex networks as modules. This modular approach allows for the construction of more sophisticated models that can handle various NLP tasks.\n",
      "\n",
      "4. **Embeddings**:\n",
      "   - Inputs to RNNs often consist of sequences of word or character embeddings, which are vector representations of words or characters. These embeddings help the network understand the semantic meaning of the input text.\n",
      "\n",
      "In summary, neural networks in NLP are used for tasks like sentiment analysis and language modeling by leveraging feedforward networks and RNNs. These networks process input text through embeddings and can be combined modularly to build more complex and effective models.\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T09:22:34.162582Z",
     "start_time": "2025-07-15T09:22:33.371577Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query = \"who author this book\"\n",
    "response = rag_pipeline.invoke(query)\n",
    "\n",
    "print(\"Answer:\")\n",
    "print(response[\"result\"])"
   ],
   "id": "ffbdeaf4f8a2e171",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      "The book \"Selected Papers of J. R. Firth\" was authored by J. R. Firth. It was published by Longman in Harlow in 1968.\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T09:22:42.618321Z",
     "start_time": "2025-07-15T09:22:39.469033Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query = \"this book explain the lstm and rnn\"\n",
    "response = rag_pipeline.invoke(query)\n",
    "\n",
    "print(\"Answer:\")\n",
    "print(response[\"result\"])"
   ],
   "id": "33c132233e14cce9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      "Yes, the provided context explains both Long Short-Term Memory (LSTM) networks and Recurrent Neural Networks (RNNs). Here are some key points covered:\n",
      "\n",
      "1. **RNNs (Recurrent Neural Networks):**\n",
      "   - Basic neural units used in feedforward and simple recurrent networks.\n",
      "   - Bidirectional RNNs are mentioned, which process sequences in both forward and backward directions to capture more context.\n",
      "\n",
      "2. **LSTMs (Long Short-Term Memory):**\n",
      "   - LSTMs are an advanced type of RNN unit.\n",
      "   - They have become the standard for modern systems using recurrent networks due to their effectiveness in capturing long-term dependencies.\n",
      "   - The context mentions that LSTMs are trained using backpropagation and are more commonly used than basic RNNs in practice.\n",
      "\n",
      "The text also discusses the application of these architectures in various tasks and summarizes common RNN and LSTM architectures used in Natural Language Processing (NLP).\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T09:23:04.033677Z",
     "start_time": "2025-07-15T09:23:00.271646Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query = \"who best naive bays or transformer\"\n",
    "response = rag_pipeline.invoke(query)\n",
    "\n",
    "print(\"Answer:\")\n",
    "print(response[\"result\"])"
   ],
   "id": "37ab015ac908bd0b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      "The choice between Naive Bayes and Transformers depends on the specific task and context:\n",
      "\n",
      "1. **Naive Bayes**:\n",
      "   - **Pros**: Simple to implement, fast to train, and can perform well on small datasets or short documents. It is also efficient for larger documents or datasets and often makes correct classification decisions despite less accurate probabilities.\n",
      "   - **Cons**: Makes strong independence assumptions between features, which may not hold true in many real-world scenarios. Generally less accurate than more complex models like logistic regression or Transformers.\n",
      "\n",
      "2. **Transformers**:\n",
      "   - **Pros**: Highly accurate and effective for a wide range of tasks, especially in natural language processing (NLP). They can capture complex patterns and dependencies in data due to their multi-head attention mechanisms.\n",
      "   - **Cons**: More computationally intensive and require significant resources for training and fine-tuning. They are also more complex to implement and understand compared to simpler models like Naive Bayes.\n",
      "\n",
      "In summary, if you have a small dataset or need a quick and simple solution, Naive Bayes might be sufficient and even perform well. However, for more complex tasks and larger datasets where accuracy is crucial, Transformers are generally the better choice.\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T09:23:17.989905Z",
     "start_time": "2025-07-15T09:23:16.725304Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query = \"In this book what the chapter number for  vector semantic\"\n",
    "response = rag_pipeline.invoke(query)\n",
    "\n",
    "print(\"Answer:\")\n",
    "print(response[\"result\"])"
   ],
   "id": "7139c4ce82c0388a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      "The provided context does not specify the chapter number for vector semantics. It only mentions that vector semantics is discussed in the text, but the exact chapter number is not given. Therefore, I cannot provide the chapter number based on the information available.\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T09:23:27.800148Z",
     "start_time": "2025-07-15T09:23:24.432688Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query = \"what the transformer use case\"\n",
    "response = rag_pipeline.invoke(query)\n",
    "\n",
    "print(\"Answer:\")\n",
    "print(response[\"result\"])"
   ],
   "id": "8b071d8c5ab12f0e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      "The context provided describes the architecture and components of a transformer model, particularly focusing on its use in language modeling. Here are the key use cases for transformers based on the given context:\n",
      "\n",
      "1. **Language Modeling**: Transformers are used to predict the next token in a sequence. This involves encoding input tokens, passing them through stacked transformer blocks, and using a language model head to generate logits for predicting the next token.\n",
      "\n",
      "2. **Self-Attention Mechanisms**: Transformers utilize multi-head attention, a form of self-attention, to process input vectors. This mechanism allows the model to weigh the relevance of prior tokens when processing the current token, making it highly effective for tasks requiring contextual understanding.\n",
      "\n",
      "3. **Sequence Processing**: Transformers are designed to handle sequences of data, making them suitable for tasks involving sequential input, such as text generation, translation, and other natural language processing (NLP) tasks.\n",
      "\n",
      "In summary, the primary use case of transformers, as described in the context, is for language modeling and tasks that require understanding and generating sequential data through self-attention mechanisms.\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T09:23:38.728899Z",
     "start_time": "2025-07-15T09:23:33.579868Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query = \"what the naive bays use case\"\n",
    "response = rag_pipeline.invoke(query)\n",
    "\n",
    "print(\"Answer:\")\n",
    "print(response[\"result\"])"
   ],
   "id": "68fa742aff4101ea",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      "Naive Bayes has several use cases, particularly in text classification and scenarios involving smaller datasets or documents. Here are some key use cases based on the provided context:\n",
      "\n",
      "1. **Text Classification**: Naive Bayes is commonly used for classifying text documents. It can efficiently handle tasks like spam detection, sentiment analysis, and topic classification.\n",
      "\n",
      "2. **Small Datasets**: Naive Bayes performs well on very small datasets, sometimes even better than more complex models like logistic regression.\n",
      "\n",
      "3. **Short Documents**: It is effective for classifying short documents, making it suitable for applications like email filtering or social media post categorization.\n",
      "\n",
      "4. **Speed and Simplicity**: Naive Bayes is easy to implement and very fast to train because it lacks an optimization step, making it a good choice for applications where training speed and simplicity are important.\n",
      "\n",
      "5. **Baseline Model**: Due to its simplicity and speed, Naive Bayes is often used as a baseline model for comparison with more complex algorithms.\n",
      "\n",
      "These characteristics make Naive Bayes a versatile and practical choice for various classification tasks, especially in contexts where computational resources are limited or where the dataset size is small.\n"
     ]
    }
   ],
   "execution_count": 20
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
