{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-15T08:17:17.139331Z",
     "start_time": "2025-07-15T08:17:16.379611Z"
    }
   },
   "source": [
    "import os\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import SentenceTransformersTokenTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain.chains import RetrievalQA\n",
    "from utils import clean\n",
    "from dotenv import load_dotenv"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T08:17:17.343256Z",
     "start_time": "2025-07-15T08:17:17.337132Z"
    }
   },
   "cell_type": "code",
   "source": "load_dotenv()",
   "id": "17b8828b6f6e9f38",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T08:17:19.293099Z",
     "start_time": "2025-07-15T08:17:19.289807Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dir = \"../../documents\"\n",
    "documents_path = os.listdir(dir)\n",
    "documents_path = [f\"{dir}/{file}\" for file in documents_path]"
   ],
   "id": "417949d5084d6f1f",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T08:17:25.973851Z",
     "start_time": "2025-07-15T08:17:20.993369Z"
    }
   },
   "cell_type": "code",
   "source": [
    "documents = []\n",
    "for file in documents_path:\n",
    "    loader = PyPDFLoader(file)\n",
    "    loaded_docs = loader.load()\n",
    "    \n",
    "    for doc in loaded_docs:\n",
    "        doc.page_content = clean(doc.page_content)\n",
    "    \n",
    "    documents.extend(loaded_docs)"
   ],
   "id": "21e55c19daa2de7f",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "text_splitter = SentenceTransformersTokenTextSplitter(tokens_per_chunk=300, chunk_overlap=30)\n",
    "chunks = text_splitter.split_documents(documents)"
   ],
   "id": "414fef6a67e26d5b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T08:18:01.776175Z",
     "start_time": "2025-07-15T08:17:59.198763Z"
    }
   },
   "cell_type": "code",
   "source": [
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "# embeddings = embedding_model.embed_documents([chunk.page_content for chunk in chunks])"
   ],
   "id": "27e4c9975e63a432",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T08:18:14.775246Z",
     "start_time": "2025-07-15T08:18:03.280704Z"
    }
   },
   "cell_type": "code",
   "source": "vectorstore = FAISS.from_documents(documents=chunks, embedding=embedding_model)",
   "id": "f3d02e8f0d8f678b",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T08:18:26.505173Z",
     "start_time": "2025-07-15T08:18:26.485892Z"
    }
   },
   "cell_type": "code",
   "source": [
    "retriever  = vectorstore.as_retriever()\n",
    "llm = OllamaLLM(model=\"llama3.2:1b\")\n",
    "\n",
    "rag_pipeline = RetrievalQA.from_chain_type(llm=llm, retriever=retriever, return_source_documents=True)"
   ],
   "id": "2191aa1393badfd7",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T08:18:46.604836Z",
     "start_time": "2025-07-15T08:18:39.342034Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query = \"how use nural network in nlp\"\n",
    "response = rag_pipeline.invoke(query)\n",
    "\n",
    "print(\"Answer:\")\n",
    "print(response[\"result\"])"
   ],
   "id": "920aca02a869a1e5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      "I don't know. \n",
      "\n",
      "This text primarily discusses the application of neural networks (specifically recurrent neural networks) in Natural Language Processing (NLP), but it does not specifically explain how neural networks are used in NLP or provide a detailed explanation of their role in language modeling, sentiment analysis, and other tasks. The text jumps directly into discussing the use of neural networks in these applications without providing a step-by-step explanation of how they work in NLP.\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T08:19:16.182395Z",
     "start_time": "2025-07-15T08:19:15.300924Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query = \"who author this book\"\n",
    "response = rag_pipeline.invoke(query)\n",
    "\n",
    "print(\"Answer:\")\n",
    "print(response[\"result\"])"
   ],
   "id": "ffbdeaf4f8a2e171",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      "I don't know, as I couldn't find any information about the author of this text.\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T08:19:25.689145Z",
     "start_time": "2025-07-15T08:19:24.355754Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query = \"this book explain the lstm and rnn\"\n",
    "response = rag_pipeline.invoke(query)\n",
    "\n",
    "print(\"Answer:\")\n",
    "print(response[\"result\"])"
   ],
   "id": "33c132233e14cce9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      "I don't know whether the question refers to \"LSTM\" (Long Short-Term Memory) or \"RNN\" (Recurrent Neural Network), as they are often used interchangeably in popular contexts. However, based on the provided text, it appears that the book focuses primarily on RNN architectures and their applications.\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T08:19:48.439773Z",
     "start_time": "2025-07-15T08:19:47.309979Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query = \"who best naive bays or transformer\"\n",
    "response = rag_pipeline.invoke(query)\n",
    "\n",
    "print(\"Answer:\")\n",
    "print(response[\"result\"])"
   ],
   "id": "37ab015ac908bd0b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      "I don't know, I'm not familiar with the specific context of this question and don't want to provide an incorrect answer. Can you please provide more information or clarify which part of the text you are referring to? I'll do my best to help.\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T08:19:56.603689Z",
     "start_time": "2025-07-15T08:19:55.200248Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query = \"In this book what the chapter number for  vector semantic\"\n",
    "response = rag_pipeline.invoke(query)\n",
    "\n",
    "print(\"Answer:\")\n",
    "print(response[\"result\"])"
   ],
   "id": "7139c4ce82c0388a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      "I don't know. The question is about the concept of \"document matrix\" and how it relates to vector semantics in the context of NLP, but I'm not provided with enough information to answer the specific question about the chapter number for \"vector semantic\".\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T08:20:10.416286Z",
     "start_time": "2025-07-15T08:20:08.999124Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query = \"what the transformer use case\"\n",
    "response = rag_pipeline.invoke(query)\n",
    "\n",
    "print(\"Answer:\")\n",
    "print(response[\"result\"])"
   ],
   "id": "8b071d8c5ab12f0e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      "I don't know. The text does not explicitly state a particular use case for transformers, but it does mention that they can be used to build language models and that they have a wide context window, which could be used for various applications such as machine translation or text summarization. However, without more information or context, it is difficult to determine a specific use case.\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T08:20:14.421824Z",
     "start_time": "2025-07-15T08:20:13.558396Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query = \"what the naive bays use case\"\n",
    "response = rag_pipeline.invoke(query)\n",
    "\n",
    "print(\"Answer:\")\n",
    "print(response[\"result\"])"
   ],
   "id": "68fa742aff4101ea",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      "I don't know, since this question requires specific knowledge of the Multinomial Naive Bayes classiÔ¨Åer and its application to text classification tasks.\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T08:21:04.794740Z",
     "start_time": "2025-07-15T08:21:02.350845Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query = \"what the self attention\"\n",
    "response = rag_pipeline.invoke(query)\n",
    "\n",
    "print(\"Answer:\")\n",
    "print(response[\"result\"])"
   ],
   "id": "339a5774ae6595a7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      "The final set of equations for computing self-attention in a single self-attention output vector ai from a single input vector xi is as follows:\n",
      "\n",
      "1. score(xi, xj) = qi ¬∑ kj‚àödk (9. 11)\n",
      "2. Œ±i j = softmax(score(xi, xj)) [UNK] ‚â§ i (9. 12)\n",
      "3. headi = [UNK] j‚â§i Œ±i jvj (9. 13)\n",
      "\n",
      "These equations calculate the attention score for each element ai in the output vector by summing the products of the query and key values and taking the exponential of half of these sums, which is equivalent to applying softmax to the weighted dot product.\n",
      "\n",
      "And the range over the entire input, as shown in fig. 11.1b:\n",
      "\n",
      "a) A causal self-attention layer\n",
      "b) A bidirectional self-attention layer\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T08:21:58.464569Z",
     "start_time": "2025-07-15T08:21:57.249652Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query = \"what the mask in transformer\"\n",
    "response = rag_pipeline.invoke(query)\n",
    "\n",
    "print(\"Answer:\")\n",
    "print(response[\"result\"])"
   ],
   "id": "42368e16ea205c75",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      "I don't know. The text does not explicitly state what the mask in a transformer block is or how it is calculated. It only mentions that \"the masked language model training\" includes selecting three input tokens and replacing one with an unrelated word, but it does not provide information about the mask itself.\n"
     ]
    }
   ],
   "execution_count": 19
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
